{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-2ac25358d660>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-2ac25358d660>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    Student name: Masinde Victor Kiprono\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Student name: Masinde Victor Kiprono\n",
    "\n",
    "Student pace: Hybrid\n",
    "\n",
    "Instructor name: Maryann Mwikali\n",
    "\n",
    "# Predicting Customer Churn For SyriaTel Company\n",
    "\n",
    "## Business Understanding\n",
    "This project deals with a company, SyriaTel, that wants to know more about their customer churn. Customers leave a company due to different reasons and my project aims to uncover the reasons and predict customer churn. The company can then use the information gained from this project to work on retaining their customers.\n",
    "\n",
    "## Import The Necessary Libraries to Notebook\n",
    "For this project, I am going to use data that has already been collected and stored in kaggle. The data is stored in csv format. I will import the necessary libararies that will enable me read my data from the csv file. I will also import other libraries that will be of help to me in editing my data and visualizing it. I will also import some libraries from **scikit learn** that will help me in **modelling**\n",
    "\n",
    "# Import libraries necessary for your project\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "sns.set_style('darkgrid')\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.tree import DecisionTreeClassifier,plot_tree\n",
    "\n",
    "\n",
    "I will use the Libraries above to read the contents of the csv file in folder named df to my notebookmin preparation for analysis.I will create a variable `df` where I will save my data. After saving the data inside my variable, I will go ahead and check the structure of our data by calling `df.head()` which shows us the preview of our data.I\n",
    "\n",
    "#Read the data into the notebook using pandas\n",
    "df=pd.read_csv('Customer churn.csv')\n",
    "df.head()\n",
    "\n",
    "## Data understanding\n",
    "I will use different built in panda methods to check for the structure of my data. I will inspect the number of rows and columns. I will also check for the summary of my data. \n",
    "\n",
    "This dataset was sourced from kaggle and it has 3333 rows and 21 columns. The dataset has dsata recorded in different data type including float, intergers and objects. The columns are properly named showing what happens in the communication sector.\n",
    "\n",
    "#Check for the data summary\n",
    "df.info()\n",
    "\n",
    "#Check for the statistical summary of the data\n",
    "df.describe()\n",
    "\n",
    "#Check for the number of columns and rows\n",
    "df.shape\n",
    "\n",
    "#print the names of columns in our data\n",
    "df.columns\n",
    "\n",
    "## Data cleaning\n",
    "We check our data to see if it ready for modelling. The data needs to be free from duplicates, missing values and wrongly recorded data. Unnecessary columns are also dropped at this point.\n",
    "\n",
    "#Checking for duplicates\n",
    "df.duplicated().sum()\n",
    "\n",
    "#Checking for missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "state and area code both play the same role which is showing the geographical characteristics of the customer. We can drop state and remain with area code. This way we ensure that there wont be repetitive features in our model.\n",
    "\n",
    "#Drop the state column\n",
    "df=df.drop(columns=['state'],axis=1)\n",
    "\n",
    "checking the column containing phone numbers, we notice that it is recorded with a '-'. Fter removing it, we want to make this columns to be our index since phone numbers are unique to each customer and can be our identifiers here.\n",
    "\n",
    "# remove the '-' in phone number column\n",
    "# Convert from objects to interger\n",
    "df['phone number'] = df['phone number'].str.replace('-', '').astype(int) \n",
    "df.set_index('phone number', inplace=True)\n",
    "\n",
    "#Confirm if the column has been set as index\n",
    "df.head()\n",
    "\n",
    "## Explolatory data analysis\n",
    " We will use `univariate`, `bivariate`, and `multivariate` analysis to perform a thorough investigation of the data in this section.\n",
    "\n",
    "Finding potential `correlations` between the features and variable distribution is the goal of this kind of data exploration, which will be crucial for feature engineering and modelling. Features that have a high correlation with the target oare often good for building basline models.\n",
    "\n",
    "#Check for the correlation of variables \n",
    "df.corr().churn\n",
    "\n",
    "#correlation matrix \n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Generate the correlation heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\")\n",
    "plt.title('Correlation Matrix between Variables')\n",
    "plt.show();\n",
    "\n",
    "# Checking the number of customers who churned and who remained\n",
    "plt.figure(figsize=(10,8))\n",
    "df['churn'].value_counts().plot(kind='bar', edgecolor='black')\n",
    "plt.xlabel('customer churn')\n",
    "plt.ylabel('No of Customers')\n",
    "plt.title('Histogram of Customer churn');\n",
    "\n",
    "df['churn'].value_counts()\n",
    "\n",
    "The graph above shows that there are more customers who remained in the company(2850) as compared to hose who terminated their contracts. Using this column in our model for logistic regression could introduce a class imbalance but that can be handled using methods like `SMOTE`\n",
    "\n",
    "## Modelling\n",
    "\n",
    "\n",
    "For classification model, my target variable will be in form of classes(False and True). For this to be used in a model, it must first be transformed to numerics. It will be a `Binary classification` since it has only two categorical variables. 0 will represent false while 1 will represent true\n",
    "\n",
    "\n",
    "\n",
    "df['churn'] = df['churn'].astype(int)\n",
    "df['churn'].value_counts()\n",
    "\n",
    "Our model cannot work with categorical variables in training and testing\n",
    "\n",
    "we need to get dummies for categorical columns and drop the first dummie, this will be used as the reference class.\n",
    "\n",
    "#convert area_code, international plan, and voice_mail_plan to integers 1s and 0s\n",
    "df = pd.get_dummies(df, columns=['area code', 'international plan', 'voice mail plan'],drop_first=True)\n",
    "df.head()\n",
    "\n",
    "A model has features and the target. We need to separate them in preparation for mdoel feeding. `X` will be assigned to features while `y` will be assigned to the target variable \n",
    "\n",
    "y= df['churn']\n",
    "X=df.drop(columns=('churn'))\n",
    "\n",
    "Now that we have our data ready, we split it into two. This is to get data for `training` the model and another set for `testing` the model to see if it is effecient in generalising the model .For the training set we take 80% of our data since we want the model to use it to learn the underlying patterns. The test set can be 20% of our original data. Pass a random state in the formula for reproducibility when the code is run again.\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "## 1. LOGISTIC REGRESSION\n",
    "**1.1 Baseline Model**\n",
    "\n",
    "This is the logistic regression model without tuning any of the parameters\n",
    "\n",
    "#Perfom scaling for the features\n",
    "scaler=StandardScaler()\n",
    "X_train_scaled=scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "#create an object for logistic regression\n",
    "logreg= LogisticRegression()\n",
    "\n",
    "#fit the model with your features and target variables for training data\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "\n",
    "Once we have fitted the model, we can go ahead and use it together with `X_test` to make a `prediction(y_pred)`. We will then use this predicted value and compare it with our `real y(y_test)` and calculate the accuracy of our model. We are using the data from our test set to see how our model perfoms with unseen data. This will give us atrue picture of if our model has learnt the underlying patterns well or not.\n",
    "\n",
    "#Make a prediction (y_pred) using the model\n",
    "y_pred= logreg.predict(X_test_scaled)\n",
    "\n",
    "###### Evaluating the model\n",
    "Having the predicted y, we can now go ahead and evaluate our model. We want to see the  variation between our predicted value and our real value. We can calculate for **accuracy, confusion matrix** which shows us how well the model predicts the values in thneir correct classes`(True positive, False positive, True Negative and False Negative)`. We can also calculate the **classification report**\n",
    "\n",
    "#Calculate for the accuracy of the model.\n",
    "accuracy= accuracy_score(y_test,y_pred)\n",
    "accuracy\n",
    "\n",
    "The ratio of correctly predicted instances to total instances is 85.76% . Accuracy always shows us how well our model is in predicting both classes and the higher the value the better. It can be misleading at times tho and should not be used alone. \n",
    "\n",
    "#Work out the confusion matrix for the baseline model.\n",
    "conf_matrix= confusion_matrix(y_test,y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "#We can visusalize the confusion matrix\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(conf_matrix,annot=True, fmt=\"d\", cmap='Blues', cbar=False,xticklabels=[\"Not Churned\", \"Churned\"],\n",
    "            yticklabels=[\"Not Churned\", \"Churned\"])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix of Test Data');\n",
    "\n",
    "Our confusion matrix has picked 667 samples and out of this it has:\n",
    "\n",
    "    561 correctly predicted churned instances.\n",
    "    99 incorrectly predicted churned intstances.\n",
    "    2 correctly predicted not churned instances.\n",
    "    5 incorrectly predicted not churned instances.\n",
    "\n",
    "#Calculate classification reports\n",
    "class_report= classification_report(y_test,y_pred)\n",
    "print(class_report)\n",
    "\n",
    "class 1 - churned class\n",
    "\n",
    "class 0-  class not churned\n",
    "\n",
    "The precision for class 0 is 85% while that of class 1 is 29%.\n",
    "This means that out of instances predicted as class 1, 29% were from class 1.\n",
    "Out of the instances predicted as class 0, 85% were actually from class \n",
    "\n",
    "The recall for class 0 is 99% while that of class 1 is 2%.\n",
    "This means that Out of all actual instances of class 0, 99% were correctly identified by the model.\n",
    "Out of all actual instances of class 1, 2% were correctly identified by the model.\n",
    "\n",
    "The f1 score of class 0 is 92% while that of class 1 is 4%\n",
    "The harmonic mean of precision and recall for class 0 is 92%\n",
    "The harmonic mean of precision and recall for class 1 is 4%\n",
    "\n",
    "`ROC CURVE AND AUC`\n",
    "\n",
    "Two crucial instruments for assessing the effectiveness of binary classification models are the Receiver Operating Characteristic (ROC) curve and the Area Under the Curve (AUC).\n",
    "ROC plots the True Positive Rate(TPR) against the False Positive Rate(FPR). The more this curve is towards the top left corner, the better the perfomance of the model.\n",
    "\n",
    "The AUC provides a single value to help in gauging the model perfomance.A value of 1 shows that the model distinguishes well between negative and positive samples making a perfect classifier. A value of 0.5 shows that the model is equal to random guessing and will not be good for classification. That of above 0.5 means that the model is better than random guessing.\n",
    "\n",
    "\n",
    "#Plotting the ROC curve and AUC\n",
    "\n",
    "#predict probabilies of class churned\n",
    "y_prob= logreg.predict_proba(X_test_scaled)[:,1]\n",
    "#Calculate the ROC curve\n",
    "fpr,tpr,thresholds = roc_curve(y_test, y_prob)\n",
    "#We can also calculate the AUC\n",
    "roc_auc = auc(fpr,tpr)\n",
    "\n",
    "#Plot the graph\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "plt.plot(fpr,tpr,color='r',label=f\"ROC Curve(AUC={roc_auc:.2f})\")\n",
    "plt.plot([0,1],[0,1],linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characterustic Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "In our case, the AUC is 0.72, which is greater than 0.5. This shows that the logistic regression model has reasonable discriminatory power in distinguishing between churned and not churned samples. An AUC of 0.72 suggests that the model has a good ability to rank the predictions, and it performs significantly better than random guessing.\n",
    "\n",
    "High accuracy, precision, and recall for class 0 demonstrate how well the model predicts the negative class (not churned).\n",
    "However, as evidenced by the low precision, recall, and F1-score values for class 1, it performs badly for the positive class (churned).\n",
    "Put otherwise, a significant portion of consumers who are churned are not included in the model, resulting in false negatives. It is not accurately identifying the clients who have left.\n",
    "\n",
    "This model is better than guessing but can have huge implications to the business as it fails to predict churned customers on a significant level\n",
    "\n",
    "##### Tuning the logistic regression model\n",
    " *Using SMOTE technique\n",
    " \n",
    " SMOTE is a technique that adresses target class imbalance by generating sysnthetic samples for the minority class. It does this by replicating the samples in the minority class. After doing this, Both classes wwill have equal values therefore adressing class imbalance. We can now create another model using these values. y_test remain untouched so that it can  still represent the real world data when we are testing the perfomance of the model.\n",
    "\n",
    "#Balance the target classes using SMOTE \n",
    "smote =SMOTE(k_neighbors=5, random_state=42,sampling_strategy='minority')\n",
    "\n",
    "#Fit SMOTE to the model.\n",
    "X_train_bal,y_train_bal = smote.fit_resample(X_train_scaled, y_train)\n",
    "y_train_bal.value_counts()\n",
    "\n",
    "**Tuned Model**\n",
    "\n",
    "We want to create a model with tuned parameters then we will compare it with our baseline to see if there are improvements\n",
    "\n",
    "#Create an object for this model\n",
    "logreg1= LogisticRegression()\n",
    "\n",
    "#Fit the model\n",
    "logreg1.fit(X_train_bal,y_train_bal)\n",
    "\n",
    "#Make predictions to help in calculating accuracy\n",
    "y_pred1 = logreg1.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "we proceed and evaluate the perfomance of the model. It gives us a way of comparing this with the first model.\n",
    "\n",
    "#Calculate Accuracy of the tuned model\n",
    "accuracy1= accuracy_score(y_test,y_pred1)\n",
    "accuracy1\n",
    "\n",
    "#Calculate the confusion matrix of the tuned model\n",
    "conf_matrix1= confusion_matrix(y_test,y_pred1)\n",
    "conf_matrix1\n",
    "\n",
    "#We can visusalize the confusion matrix\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(conf_matrix1,annot=True, fmt=\"d\", cmap='Set1_r', cbar=False,xticklabels=[\"Not Churned\", \"Churned\"],\n",
    "            yticklabels=[\"Not Churned\", \"Churned\"])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix of Test Data');\n",
    "\n",
    "#Calculate the classification report of the tuned model\n",
    "class_report1= classification_report(y_test,y_pred1)\n",
    "print(class_report1)\n",
    "\n",
    "#Plotting the ROC curve and AUC\n",
    "\n",
    "#predict probabilies of class churned\n",
    "y_prob1= logreg1.predict_proba(X_test_scaled)[:,1]\n",
    "#Calculate the ROC curve\n",
    "fpr1,tpr1,thresholds1 = roc_curve(y_test, y_prob1)\n",
    "#We can also calculate the AUC\n",
    "roc_auc1 = auc(fpr1,tpr1)\n",
    "\n",
    "#Plot the graph\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "plt.plot(fpr1,tpr1,color='r',label=f\"ROC Curve(AUC={roc_auc1:.2f})\")\n",
    "plt.plot([0,1],[0,1],linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characterustic Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "## 2. DECISION TREE CLASSIFIER\n",
    "\n",
    "just like logistic regression, we will train, test and evaluate the Decision Tree Classifier. We will start by calling the DecisionTreeClassifier and feed the model with both X_train and y_train data that we obtained earlier after adressing class imbalance.\n",
    "\n",
    "#create an object for decision tree\n",
    "dtc= DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "#fit the model\n",
    "dtc_model=dtc.fit(X_train_bal,y_train_bal)\n",
    "\n",
    "#Make a prediction using test data\n",
    "y_pred2 = dtc_model.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "After fitting the model, we can use the predicted y together with y_test to calculate accuracy, precision, recall and f1_score \n",
    "\n",
    "#Calculate accuracy \n",
    "accuracy2=accuracy_score(y_test, y_pred2)\n",
    "accuracy2\n",
    "\n",
    "#Work out the confusion matrix for the  model.\n",
    "conf_matrix2= confusion_matrix(y_test,y_pred2)\n",
    "print(conf_matrix2)\n",
    "\n",
    "#We can visusalize the confusion matrix\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(conf_matrix2,annot=True, fmt=\"d\", cbar=False,xticklabels=[\"Not Churned\", \"Churned\"],\n",
    "            yticklabels=[\"Not Churned\", \"Churned\"])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix of Test Data');\n",
    "\n",
    "#Calculate class report metrics\n",
    "class_report2= classification_report(y_test,y_pred2)\n",
    "print(class_report2)\n",
    "\n",
    "#plot the ROC curve and AUC\n",
    "\n",
    "#predict probabilies of class churned\n",
    "y_prob2= dtc_model.predict_proba(X_test_scaled)[:,1]\n",
    "#Calculate the ROC curve\n",
    "fpr2,tpr2,thresholds2 = roc_curve(y_test, y_prob2)\n",
    "#We can also calculate the AUC\n",
    "roc_auc2 = auc(fpr2,tpr2)\n",
    "\n",
    "#Plot the graph\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "plt.plot(fpr2,tpr2,color='b',label=f\"ROC Curve(AUC={roc_auc2:.2f})\")\n",
    "plt.plot([0,1],[0,1],linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characterustic Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20, 10))  # Specify the figure size\n",
    "plot_tree(dtc_model, filled=True, feature_names=X.columns, class_names=['class_0', 'class_1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
